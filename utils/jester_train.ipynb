{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# import keras_tuner as kt\n",
    "\n",
    "\n",
    "JESTER_DATASET_DIR_PATH = os.path.join(\"..\", \"..\", \"datasets\")\n",
    "TRAIN_INFO_PATH = os.path.join(JESTER_DATASET_DIR_PATH, \"info\", \"jester-v1-train.csv\")\n",
    "VAL_INFO_PATH = os.path.join(JESTER_DATASET_DIR_PATH, \"info\", \"jester-v1-validation.csv\")\n",
    "TEST_INFO_PATH = os.path.join(JESTER_DATASET_DIR_PATH, \"info\", \"labeled-test.csv\")\n",
    "LABELS_INFO_PATH = os.path.join(JESTER_DATASET_DIR_PATH, \"info\", 'jester-v1-labels.csv')\n",
    "VIDEO_DIR_PATH = os.path.join(JESTER_DATASET_DIR_PATH, \"data\")\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(JESTER_DATASET_DIR_PATH, \"info\", \"train_df.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(JESTER_DATASET_DIR_PATH, \"info\", \"val_df.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(JESTER_DATASET_DIR_PATH, \"info\", \"test_df.csv\"))\n",
    "\n",
    "columns = [\"label\"]\n",
    "labels_info = pd.read_csv(os.path.join(JESTER_DATASET_DIR_PATH, \"info\", \"jester-v1-labels.csv\"), names=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd20a9a-c088-4e81-8492-e82adc29a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af92e4e-93f7-4217-a008-ddd3e20d2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1950c744-d831-4e80-a08c-37b081d4e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe948c8d894f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_SIZE = (121_500 + len(val_df) + len(test_df) ) // 1\n",
    "TRAIN_SET_SIZE = 121_500 // 1\n",
    "VAL_SET_SIZE = len(val_df) // 1\n",
    "TEST_SET_SIZE = len(test_df) // 1\n",
    "MIN_SEQ_LEN = 30\n",
    "CLASSES = [i for i in range(27)]\n",
    "CLASSES_PERCENTAGE = [1/len(CLASSES) for _ in range(len(CLASSES))]\n",
    "CLASSES_WITH_PERCENTAGE = {cls: percentage for cls, percentage in zip(CLASSES, CLASSES_PERCENTAGE)}\n",
    "TRAIN_CLASSES_WITH_AMOUNT = {cls: int(percentage * TRAIN_SET_SIZE) for cls, percentage in zip(CLASSES, CLASSES_PERCENTAGE)}\n",
    "TRAIN_CLASSES_WITH_AMOUNT[26] = TRAIN_CLASSES_WITH_AMOUNT.get(26) + 4500 // 1\n",
    "# TRAIN_CLASSES_WITH_AMOUNT[14] = TRAIN_CLASSES_WITH_AMOUNT.get(14) - 1300 // 1\n",
    "# TRAIN_CLASSES_WITH_AMOUNT[15] = TRAIN_CLASSES_WITH_AMOUNT.get(15) - 1300 // 1\n",
    "VAL_CLASSES_WITH_AMOUNT = {cls: int(percentage * VAL_SET_SIZE) for cls, percentage in zip(CLASSES, CLASSES_PERCENTAGE)}\n",
    "VAL_CLASSES_WITH_AMOUNT[26] = VAL_CLASSES_WITH_AMOUNT.get(26) + 450 // 1\n",
    "TEST_CLASSES_WITH_AMOUNT = {cls: int(percentage * TEST_SET_SIZE) for cls, percentage in zip(CLASSES, CLASSES_PERCENTAGE)}\n",
    "TEST_CLASSES_WITH_AMOUNT[26] = TEST_CLASSES_WITH_AMOUNT.get(26) + 450 // 1\n",
    "CLASS_MAPPING = {cls: idx for idx, cls in enumerate(CLASSES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593df5a6f424424",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SET_SIZE / (SET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dfa588-80c0-4437-931b-3d5a4e8ad0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_CLASSES_WITH_AMOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a6463374c73c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CLASSES_WITH_AMOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b8c30-68da-4ea8-86f3-a3d1d50437e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CLASSES_WITH_AMOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec882584a2308bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(dataframe: pd.DataFrame, subset_info: dict[int, int], min_seq_len: int,\n",
    "                  training: bool) -> pd.DataFrame:\n",
    "    def _get_longer_seq_len_than(df: pd.DataFrame, seq_len: int) -> pd.DataFrame:\n",
    "        return df[df[\"seq_len\"] >= seq_len]\n",
    "\n",
    "    def _get_df_subset(df: pd.DataFrame, classes_with_amount: dict[int, int], training: bool) -> pd.DataFrame:\n",
    "        subset_df = pd.DataFrame()\n",
    "        for key, val in classes_with_amount.items():\n",
    "            class_df = df[df[\"label_id\"] == key]\n",
    "            current_count = len(class_df)\n",
    "\n",
    "            if training:\n",
    "                if current_count < val:\n",
    "                    needed_count = val - current_count\n",
    "                    sampled_df = class_df.sample(n=needed_count, replace=True)\n",
    "                    class_df = pd.concat([class_df, sampled_df], ignore_index=True)\n",
    "                subset_df = pd.concat([subset_df, class_df.sample(n=val, replace=False)], ignore_index=True)\n",
    "            else:\n",
    "                subset_df = pd.concat([subset_df, class_df.sample(n=min(val, current_count), replace=False)],\n",
    "                                      ignore_index=True)\n",
    "\n",
    "        return subset_df.sample(frac=1, ignore_index=True)\n",
    "\n",
    "    # new_df = _get_longer_seq_len_than(dataframe, min_seq_len)\n",
    "    new_df = _get_df_subset(dataframe, subset_info, training)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "train_subset_df = preprocess_df(train_df, TRAIN_CLASSES_WITH_AMOUNT, MIN_SEQ_LEN, training=True)\n",
    "val_subset_df = preprocess_df(val_df, VAL_CLASSES_WITH_AMOUNT, MIN_SEQ_LEN, training=False)\n",
    "test_subset_df = preprocess_df(test_df, TEST_CLASSES_WITH_AMOUNT, MIN_SEQ_LEN, training=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2e395d-e076-4bbe-a8ec-3c23ebdf1dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_subset_df['label_id'].map(CLASS_MAPPING).values\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd85b7e-366f-46d3-be29-305f53a5cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "\n",
    "class_weight_dict = dict(zip(np.unique(labels), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f79faf-f64a-40d3-ae5f-f82f0242b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5faab13ac013859",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5ac992a33618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f06bc9-b6eb-4b84-ae4a-8e15e323fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9051a0fd7889dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "train_subset_df['label'].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Etykiety', fontsize=18)\n",
    "plt.ylabel('Ilość Próbek', fontsize=18)\n",
    "plt.title('Rozkład próbek w zbiorze treningowym po przetworzeniu', fontsize=22)\n",
    "ax = plt.gca()\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray')\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cls_dist_train_after.jpg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c78d4ee76b55b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "val_subset_df['label'].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Etykiety', fontsize=18)\n",
    "plt.ylabel('Ilość Próbek', fontsize=18)\n",
    "plt.title('Rozkład próbek w zbiorze walidacyjnym po przetworzeniu', fontsize=22)\n",
    "ax = plt.gca()\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray')\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cls_dist_val_after.jpg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a3ebf-207c-45c8-84be-32ecdadf151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "test_subset_df['label'].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Etykiety', fontsize=18)\n",
    "plt.ylabel('Ilość Próbek', fontsize=18)\n",
    "plt.title('Rozkład próbek w zbiorze testowym po przetworzeniu', fontsize=22)\n",
    "ax = plt.gca()\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray')\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cls_dist_test_after.jpg\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "all_df = pd.concat([train_subset_df, val_subset_df, test_subset_df])\n",
    "plt.figure(figsize=(16, 9))\n",
    "all_df['seq_len'].hist(bins=50, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Długość sekwencji', fontsize=18)\n",
    "plt.ylabel('Liczba wystąpień', fontsize=18)\n",
    "plt.title('Rozkład długości próbek w zbiorze', fontsize=22)\n",
    "ax = plt.gca()\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray')\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"jester_plots/seq_len_distribution_after.jpg\", dpi=300)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea6f1dbf953bfeb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Mean Sequence Length In Train Dataset: {train_subset_df['seq_len'].mean()}\")\n",
    "print(f\"Mean Sequence Length In Validation Dataset: {val_subset_df['seq_len'].mean()}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9aa87bb12354adb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e38092724f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_dir(df: pd.DataFrame, seq_len: int, class_mapping: dict[int, int]):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        video_path = row['path']\n",
    "        label_id = row['label_id']\n",
    "        image_paths = generate_image_paths(video_path, seq_len, row)\n",
    "        sequences.append(image_paths)\n",
    "        mapped_label_id = class_mapping[label_id]\n",
    "        labels.append(mapped_label_id)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((sequences, labels))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InputShape:\n",
    "    weight: int\n",
    "    height: int\n",
    "    channels: int\n",
    "\n",
    "    def as_tuple(self) -> tuple[int, int, int]:\n",
    "        return self.weight, self.height, self.channels\n",
    "\n",
    "\n",
    "def generate_image_paths(video_dir_path: str, seq_len: int, row: pd.Series):\n",
    "    image_paths = []\n",
    "    current_frames: int = row[\"seq_len\"]\n",
    "\n",
    "    if current_frames >= seq_len:\n",
    "        mid_point = current_frames // 2\n",
    "        start_point = max(0, mid_point - seq_len // 2)\n",
    "        end_point = start_point + seq_len\n",
    "\n",
    "        for i in range(start_point + 1, end_point + 1):\n",
    "            img_name = f\"{i:05d}.jpg\"\n",
    "            img_path = os.path.join(video_dir_path, img_name)\n",
    "            image_paths.append(img_path)\n",
    "\n",
    "    else:\n",
    "        padding_needed = seq_len - current_frames\n",
    "        left_padding = padding_needed // 2\n",
    "        right_padding = padding_needed - left_padding\n",
    "\n",
    "        most_left_img = f\"00001.jpg\"\n",
    "        most_right_img = f\"{current_frames:05d}.jpg\"\n",
    "\n",
    "        for i in range(left_padding):\n",
    "            img_path = os.path.join(video_dir_path, most_left_img)\n",
    "            image_paths.append(img_path)\n",
    "\n",
    "        for i in range(1, current_frames + 1):\n",
    "            img_name = f\"{i:05d}.jpg\"\n",
    "            img_path = os.path.join(video_dir_path, img_name)\n",
    "            image_paths.append(img_path)\n",
    "\n",
    "        for i in range(right_padding):\n",
    "            img_path = os.path.join(video_dir_path, most_right_img)\n",
    "            image_paths.append(img_path)\n",
    "\n",
    "    if len(image_paths) != seq_len:\n",
    "        raise ValueError(f\"Missing images in dir: {video_dir_path}\")\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def preprocess_frames(frames, label):\n",
    "    # flip = random.choice([True, False])\n",
    "    brightness_delta = random.uniform(-0.2, 0.2)\n",
    "    contrast_factor = random.uniform(0.8, 1.2)\n",
    "    saturation_factor = random.uniform(0.8, 1.2)\n",
    "    hue_delta = random.uniform(-0.02, 0.02)\n",
    "    noise_stddev = 0.05\n",
    "\n",
    "    augmentations = [\n",
    "        # lambda img: tf.image.flip_left_right(img) if flip else img,\n",
    "        lambda img: tf.image.adjust_brightness(img, brightness_delta),\n",
    "        lambda img: tf.image.adjust_contrast(img, contrast_factor),\n",
    "        lambda img: tf.image.adjust_saturation(img, saturation_factor),\n",
    "        lambda img: tf.image.adjust_hue(img, hue_delta),\n",
    "        lambda img: img + tf.random.normal(tf.shape(img), mean=0.0, stddev=noise_stddev)\n",
    "    ]\n",
    "\n",
    "    chosen_augmentations = random.sample(augmentations, 2)\n",
    "\n",
    "    def process_image(img):\n",
    "        for aug in chosen_augmentations:\n",
    "            img = aug(img)\n",
    "        # img = tf.cast(img, tf.float32) / 255.0\n",
    "        return img\n",
    "\n",
    "    preprocessed_images = tf.map_fn(process_image, frames, fn_output_signature=tf.float32)\n",
    "\n",
    "    return preprocessed_images, label\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def load_sequence_from_dir(image_paths: tf.Tensor, label: int, inp_shape: tuple[int, int, int]):\n",
    "    def process_image(img_path):\n",
    "        image = tf.io.read_file(img_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=inp_shape[2])\n",
    "        image = tf.image.resize(image, inp_shape[:2])\n",
    "        # image = tf.cast(image, tf.float32) / 255.0\n",
    "        return image\n",
    "\n",
    "    preprocessed_images = tf.map_fn(process_image, image_paths, fn_output_signature=tf.float32)\n",
    "\n",
    "    return preprocessed_images, label\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def one_hot_encode(path: tf.Tensor, label: tf.Tensor, classes_num: int):\n",
    "    return path, tf.one_hot(label, classes_num, dtype=tf.int32)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def remove_one_dimensions(images: tf.Tensor, label: int):\n",
    "    return tf.squeeze(images), label\n",
    "\n",
    "@tf.function\n",
    "def normalize_frames(frames, label):\n",
    "    return (tf.cast(frames, tf.float32) / 255.0), label\n",
    "\n",
    "@tf.function\n",
    "def add_dimension(frames, label):\n",
    "    frames = tf.expand_dims(frames, axis=0) \n",
    "    return frames, label\n",
    "\n",
    "def create_pipeline(df: pd.DataFrame, *, num_classes: int, image_input_shape: InputShape, seq_len: int, batch_size: int, class_mapping: dict[int, int], is_training: bool = False) -> tf.data.Dataset:\n",
    "    num_calls = tf.data.AUTOTUNE\n",
    "    ds = create_dataset_from_dir(df, seq_len=seq_len, class_mapping=class_mapping) # (list with paths strs)\n",
    "    ds = ds.map(lambda images, label: one_hot_encode(images, label, num_classes), num_parallel_calls=num_calls)\n",
    "    ds = ds.map(lambda path, label: load_sequence_from_dir(path, label, image_input_shape.as_tuple()), num_parallel_calls=num_calls) # (seq_len, width, height, channels)\n",
    "    if is_training:\n",
    "        pass\n",
    "        ds = ds.map(lambda frames, label: preprocess_frames(frames, label), num_parallel_calls=num_calls)\n",
    "    ds = ds.map(lambda frames, label: normalize_frames(frames, label), num_parallel_calls=num_calls)\n",
    "    # ds = ds.map(lambda frames, label: add_dimension(frames, label), num_parallel_calls=num_calls)\n",
    "    # ds = ds.map(lambda frames, label: preprocess_first_layer(frames, label), num_parallel_calls=num_calls)\n",
    "    # ds = ds.map(lambda frames, label: remove_one_dimensions(frames, label), num_parallel_calls=num_calls)\n",
    "    ds = ds.batch(batch_size=batch_size, drop_remainder=True)\n",
    "    # if is_training:\n",
    "    #     ds = ds.cache(\"./cache_mobilenet_train\")\n",
    "    # else:\n",
    "    #     ds = ds.cache(\"./cache_mobilenet_val\")\n",
    "    ds = ds.prefetch(num_calls)\n",
    "    return ds\n",
    "\n",
    "\n",
    "class PipelineConfig:\n",
    "    IMAGE_INPUT_SHAPE = InputShape(224, 224, 3)\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    BATCH_SIZE = 16\n",
    "    SEQ_LEN = 34\n",
    "\n",
    "\n",
    "# mobilenet_model = keras.applications.MobileNetV2(\n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_shape=PipelineConfig.IMAGE_INPUT_SHAPE.as_tuple(),\n",
    "#     pooling=\"avg\",\n",
    "#     name=\"mobilenet_v2\"\n",
    "# )\n",
    "\n",
    "# time_distributed_layer = keras.layers.TimeDistributed(mobilenet_model)\n",
    "\n",
    "# def preprocess_first_layer(frames, label):\n",
    "#     first_layer_output = time_distributed_layer(frames)\n",
    "#     return first_layer_output, label\n",
    "\n",
    "\n",
    "\n",
    "train_ds = create_pipeline(\n",
    "    train_subset_df,\n",
    "    num_classes=PipelineConfig.NUM_CLASSES,\n",
    "    image_input_shape=PipelineConfig.IMAGE_INPUT_SHAPE,\n",
    "    seq_len=PipelineConfig.SEQ_LEN,\n",
    "    batch_size=PipelineConfig.BATCH_SIZE,\n",
    "    class_mapping=CLASS_MAPPING,\n",
    "    is_training=True\n",
    ")\n",
    "\n",
    "val_ds = create_pipeline(\n",
    "    val_subset_df,\n",
    "    num_classes=PipelineConfig.NUM_CLASSES,\n",
    "    image_input_shape=PipelineConfig.IMAGE_INPUT_SHAPE,\n",
    "    seq_len=PipelineConfig.SEQ_LEN,\n",
    "    batch_size=PipelineConfig.BATCH_SIZE,\n",
    "    class_mapping=CLASS_MAPPING,\n",
    "    is_training=False\n",
    ")\n",
    "\n",
    "test_ds = create_pipeline(\n",
    "    test_subset_df,\n",
    "    num_classes=PipelineConfig.NUM_CLASSES,\n",
    "    image_input_shape=PipelineConfig.IMAGE_INPUT_SHAPE,\n",
    "    seq_len=PipelineConfig.SEQ_LEN,\n",
    "    batch_size=PipelineConfig.BATCH_SIZE,\n",
    "    class_mapping=CLASS_MAPPING,\n",
    "    is_training=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54033d6e645c879d",
   "metadata": {},
   "source": [
    "# Articles Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9740ef07-31eb-41a5-a9cc-3afa785a07e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dec678e7551560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_from_articles(input_shape: tuple[int, int], num_classes: int):\n",
    "    mobilenet_model = keras.applications.MobileNetV3Large(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=PipelineConfig.IMAGE_INPUT_SHAPE.as_tuple(),\n",
    "        include_preprocessing=True,\n",
    "        pooling=\"avg\",\n",
    "    )\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(input_shape))\n",
    "    model.add(keras.layers.TimeDistributed(mobilenet_model))\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.add(keras.layers.LSTM(units=256, return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.0001), name=\"LSTM_1\"))\n",
    "    model.add(keras.layers.Dropout(0.2, name=\"LSTM_DROPOUT_1\"))\n",
    "    model.add(keras.layers.LayerNormalization(name=\"LSTM_LNORM_1\"))\n",
    "    model.add(keras.layers.LSTM(units=256, return_sequences=True, kernel_regularizer=keras.regularizers.l2(0.0001), name=\"LSTM_2\"))\n",
    "    model.add(keras.layers.Dropout(0.2, name=\"LSTM_DROPOUT_2\"))\n",
    "    model.add(keras.layers.LayerNormalization(name=\"LSTM_LNORM_2\"))\n",
    "    model.add(keras.layers.LSTM(units=256, return_sequences=False, kernel_regularizer=keras.regularizers.l2(0.0001), name=\"LSTM_3\"))\n",
    "    model.add(keras.layers.Dropout(0.2, name=\"LSTM_DROPOUT_3\"))\n",
    "    model.add(keras.layers.LayerNormalization(name=\"LSTM_LNORM_3\"))\n",
    "    model.add(keras.layers.Dense(units=256, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(0.001), name=\"DENSE_1\"))\n",
    "    model.add(keras.layers.Dropout(0.1, name=\"DENSE_DROPOUT_1\"))\n",
    "    model.add(keras.layers.LayerNormalization(name=\"DENSE_LNORM_1\"))\n",
    "    # model.add(keras.layers.Dense(units=256, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(0.0001), name=\"DENSE_2\"))\n",
    "    # model.add(keras.layers.Dropout(0.1, name=\"DENSE_DROPOUT_2\"))\n",
    "    # model.add(keras.layers.LayerNormalization(name=\"DENSE_LNORM_2\"))\n",
    "    model.add(keras.layers.Dense(units=num_classes, name=\"DENSE_OUTPUT\"))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "        'accuracy',\n",
    "        'precision',\n",
    "        'recall',\n",
    "        tf.keras.metrics.F1Score(average='weighted')\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330eb81ab4de15a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = build_model_from_articles(input_shape=(PipelineConfig.SEQ_LEN, *PipelineConfig.IMAGE_INPUT_SHAPE.as_tuple()), num_classes=len(CLASSES))\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    monitor='val_loss',\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    'model_articles_based.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lstm_model.summary()\n",
    "\n",
    "# history = lstm_model.fit(\n",
    "#     train_ds, epochs=100,\n",
    "#     validation_data=val_ds,\n",
    "#     batch_size=PipelineConfig.BATCH_SIZE,\n",
    "#     callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "#     class_weight=class_weight_dict\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77afff11-bfd0-49d9-8cc1-bbcf7a82b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_from_articles_conv3D(input_shape: tuple[int, int, int, int], num_classes: int):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(input_shape))\n",
    "\n",
    "    # Warstwa 1 - conv3D\n",
    "    model.add(keras.layers.Conv3D(32, kernel_size=(3, 3, 3), strides=(1, 1, 1), kernel_regularizer=keras.regularizers.l2(0.0001), activation='relu', padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # Warstwa 2 - max pool\n",
    "    model.add(keras.layers.MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "#    model.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "    # Warstwa 3 - conv3D\n",
    "    model.add(keras.layers.Conv3D(64, kernel_size=(3, 3, 3), strides=(1, 1, 1), kernel_regularizer=keras.regularizers.l2(0.0001), activation='relu', padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # Warstwa 4 - max pool\n",
    "    model.add(keras.layers.MaxPooling3D(pool_size=(1, 2, 2)))\n",
    " #   model.add(keras.layers.Dropout(0.1))\n",
    "    # Warstwa 5 - conv3D\n",
    "    model.add(keras.layers.Conv3D(128, kernel_size=(3, 3, 3), strides=(1, 1, 1), kernel_regularizer=keras.regularizers.l2(0.0001), activation='relu', padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # Warstwa 6 - max pool\n",
    "    model.add(keras.layers.MaxPooling3D(pool_size=(1, 2, 2)))\n",
    " #   model.add(keras.layers.Dropout(0.1))\n",
    "    # Warstwa 7 - conv3D\n",
    "    model.add(keras.layers.Conv3D(256, kernel_size=(3, 3, 3), strides=(1, 1, 1), kernel_regularizer=keras.regularizers.l2(0.0001), activation='relu', padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    " #   model.add(keras.layers.Dropout(0.1))\n",
    "    # Warstwa 8 - conv3D\n",
    "    model.add(keras.layers.Conv3D(256, kernel_size=(3, 3, 3), strides=(1, 1, 1), kernel_regularizer=keras.regularizers.l2(0.0001), activation='relu', padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    " #   model.add(keras.layers.Dropout(0.1))\n",
    "    # Warstwa 9 - conv3D\n",
    "    model.add(keras.layers.Conv3D(256, kernel_size=(3, 3, 3), strides=(1, 1, 1), kernel_regularizer=keras.regularizers.l2(0.0001), activation='relu', padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    " #   model.add(keras.layers.Dropout(0.1))    \n",
    "    # Warstwa 10 - global max pool\n",
    "    model.add(keras.layers.GlobalMaxPooling3D())\n",
    "    # Warstwa 11 - LSTM\n",
    "    model.add(keras.layers.RepeatVector(1))\n",
    "    model.add(keras.layers.LSTM(256, kernel_regularizer=keras.regularizers.l2(0.0001), return_sequences=True))\n",
    " #   model.add(keras.layers.Dropout(0.1))\n",
    "    # Warstwa 12 - LSTM\n",
    "    model.add(keras.layers.LSTM(256, kernel_regularizer=keras.regularizers.l2(0.0001)))\n",
    "    model.add(keras.layers.LayerNormalization(name=\"DENSE_LNORM_1\"))\n",
    " #   model.add(keras.layers.Dropout(0.1))\n",
    "    # Warstwa 13 - Fully connected\n",
    "    model.add(keras.layers.Dense(units=256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.0001), name=\"DENSE_LAYER\"))\n",
    "    model.add(keras.layers.LayerNormalization(name=\"DENSE_LNORM_2\"))\n",
    " #   model.add(keras.layers.Dropout(0.1))\n",
    "    # Warstwa 14 - Fully connected (output)\n",
    "    model.add(keras.layers.Dense(units=num_classes, name=\"DENSE_OUTPUT\"))\n",
    "\n",
    "    # Optimizer and compile\n",
    "    optimizer = keras.optimizers.Adam(0.001)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            'precision',\n",
    "            'recall',\n",
    "            tf.keras.metrics.F1Score(average='weighted')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6108da970ae88f6f",
   "metadata": {},
   "source": [
    "# Plots From Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f952c58ed1b732",
   "metadata": {},
   "source": [
    "### Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9b80e06555a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Dokładność na zbiorze treningowym')\n",
    "plt.plot(history.history['val_accuracy'], label='Dokładność na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Dokładność')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.title('Krzywa Uczenia - Dokładność')\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Strata na zbiorze treningowym')\n",
    "plt.plot(history.history['val_loss'], label='Strata na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Strata')\n",
    "plt.ylim([0, max(history.history['loss'])])\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.title('Krzywa Uczenia - Strata')\n",
    "\n",
    "\n",
    "plt.savefig('training_plots_articles_based_loss_acc.png')\n",
    "\n",
    "print(\"Plots saved as 'training_plots.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1141cd6eefdc7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 25))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Dokładność na zbiorze treningowym')\n",
    "plt.plot(history.history['val_accuracy'], label='Dokładność na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Dokładność')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.title('Krzywa Uczenia - Dokładność')\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Strata na zbiorze treningowym')\n",
    "plt.plot(history.history['val_loss'], label='Strata na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Strata')\n",
    "plt.ylim([0, max(history.history['loss'])])\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.title('Krzywa Uczenia - Strata')\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.plot(history.history['precision'], label='Precyzja na zbiorze treningowym')\n",
    "plt.plot(history.history['val_precision'], label='Precyzja na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Precyzja')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.title('Krzywa Uczenia - Precyzja')\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.plot(history.history['recall'], label='Czułość na zbiorze treningowym')\n",
    "plt.plot(history.history['val_recall'], label='Czułość na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Czułość')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.title('Krzywa Uczenia - Czułość')\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.plot(history.history['f1_score'], label='F1 Score na zbiorze treningowym')\n",
    "plt.plot(history.history['val_f1_score'], label='F1 Score na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.title('Krzywa Uczenia - F1 Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_plots_articles_based_grid.png')\n",
    "\n",
    "print(\"Plots saved as 'training_plots_articles_based.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ab4306aa73e10",
   "metadata": {},
   "source": [
    "### No Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886e971d6a5bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 25))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Dokładność na zbiorze treningowym')\n",
    "plt.plot(history.history['val_accuracy'], label='Dokładność na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Dokładność')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Krzywa Uczenia - Dokładność')\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Strata na zbiorze treningowym')\n",
    "plt.plot(history.history['val_loss'], label='Strata na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Strata')\n",
    "plt.ylim([0, max(history.history['loss'])])\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Krzywa Uczenia - Strata')\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.plot(history.history['precision'], label='Precyzja na zbiorze treningowym')\n",
    "plt.plot(history.history['val_precision'], label='Precyzja na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Precyzja')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Krzywa Uczenia - Precyzja')\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.plot(history.history['recall'], label='Czułość na zbiorze treningowym')\n",
    "plt.plot(history.history['val_recall'], label='Czułość na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Czułość')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Krzywa Uczenia - Czułość')\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.plot(history.history['f1_score'], label='F1 Score na zbiorze treningowym')\n",
    "plt.plot(history.history['val_f1_score'], label='F1 Score na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Krzywa Uczenia - F1 Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_plots_articles_based_no_grid.png')\n",
    "\n",
    "print(\"Plots saved as 'training_plots_articles_based.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8f8f2454f2fcdd",
   "metadata": {},
   "source": [
    "### By one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faaebfee11844ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.plot(history.history['accuracy'], label='Dokładność na zbiorze treningowym')\n",
    "plt.plot(history.history['val_accuracy'], label='Dokładność na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Dokładność')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Krzywa Uczenia - Dokładność')\n",
    "plt.grid()\n",
    "plt.savefig('training_plots_articles_based_acc_grid.png')\n",
    "\n",
    "print(\"Plots saved as 'training_plots_articles_based.png'\")\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.plot(history.history['loss'], label='Strata na zbiorze treningowym')\n",
    "plt.plot(history.history['val_loss'], label='Strata na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Strata')\n",
    "plt.ylim([0, max(history.history['loss'])])\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Krzywa Uczenia - Strata')\n",
    "plt.grid()\n",
    "plt.savefig('training_plots_articles_based_loss.png')\n",
    "\n",
    "print(\"Plots saved as 'training_plots_articles_based.png'\")\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.plot(history.history['precision'], label='Precyzja na zbiorze treningowym')\n",
    "plt.plot(history.history['val_precision'], label='Precyzja na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Precyzja')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Krzywa Uczenia - Precyzja')\n",
    "plt.grid()\n",
    "plt.savefig('training_plots_articles_based_prec.png')\n",
    "\n",
    "print(\"Plots saved as 'training_plots_articles_based.png'\")\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.plot(history.history['recall'], label='Czułość na zbiorze treningowym')\n",
    "plt.plot(history.history['val_recall'], label='Czułość na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('Czułość')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Krzywa Uczenia - Czułość')\n",
    "plt.grid()\n",
    "plt.savefig('training_plots_articles_based_recall.png')\n",
    "\n",
    "print(\"Plots saved as 'training_plots_articles_based.png'\")\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.plot(history.history['f1_score'], label='F1 Score na zbiorze treningowym')\n",
    "plt.plot(history.history['val_f1_score'], label='F1 Score na zbiorze walidacyjnym')\n",
    "plt.xlabel('Epoka')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Krzywa Uczenia - F1 Score')\n",
    "plt.grid()\n",
    "plt.savefig('training_plots_articles_based_f1.png')\n",
    "\n",
    "print(\"Plots saved as 'training_plots_articles_based.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5bacb3-6e57-4e74-8141-1bd5530f3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el, label in test_ds:\n",
    "    print(el.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83244025f0536548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineConfig:\n",
    "    IMAGE_INPUT_SHAPE = InputShape(164, 164, 3)\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    BATCH_SIZE = 16\n",
    "    SEQ_LEN = 34\n",
    "\n",
    "lstm_model = build_model_from_articles_conv3D(\n",
    "    input_shape=(PipelineConfig.SEQ_LEN, *PipelineConfig.IMAGE_INPUT_SHAPE.as_tuple()),\n",
    "    num_classes=PipelineConfig.NUM_CLASSES\n",
    ")\n",
    "\n",
    "\n",
    "lstm_model.load_weights('model_weights-3dcnn.weights.h5')\n",
    "\n",
    "results = lstm_model.evaluate(test_ds)\n",
    "\n",
    "print(\"Test Loss:\", results[0])\n",
    "print(\"Test Accuracy:\", results[1])\n",
    "print(\"Test Precision:\", results[2])\n",
    "print(\"Test Recall:\", results[3])\n",
    "print(\"Test F1 Score:\", results[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8b14dddf28884",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    predictions = lstm_model.predict(images)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    true_classes = np.argmax(labels, axis=1) if labels.shape[-1] > 1 else labels.numpy()\n",
    "\n",
    "    y_pred.extend(predicted_classes)\n",
    "    y_true.extend(true_classes)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=range(len(CLASSES)))\n",
    "# cm = confusion_matrix(y_true, y_pred, normalize='true', labels=range(len(CLASSES)))\n",
    "\n",
    "# print(\"Confusion Matrix:\\n\", cm)\n",
    "# for images, labels in val_ds:\n",
    "#     predictions = lstm_model.predict(images)\n",
    "#     predicted_classes = np.argmax(predictions, axis=1)\n",
    "#     true_classes = np.argmax(labels, axis=1)\n",
    "\n",
    "#     y_pred.extend(predicted_classes)\n",
    "#     y_true.extend(true_classes)\n",
    "\n",
    "# # cm = confusion_matrix(y_true, y_pred, normalize='true', labels=range(len(CLASSES)))\n",
    "# cm = confusion_matrix(y_true, y_pred, labels=range(len(CLASSES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4122de678490897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "jester_labels = {}\n",
    "with open(os.path.join(JESTER_DATASET_DIR_PATH, \"info\", 'jester-v1-labels.csv')) as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        jester_labels[idx] = line.strip()\n",
    "\n",
    "display_info = [jester_labels.get(cls) for cls in CLASSES]\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_info)\n",
    "\n",
    "disp.plot(\n",
    "    cmap=plt.cm.Blues,\n",
    "    xticks_rotation=45,  \n",
    "    # values_format='.2f'\n",
    "    values_format='.0f'\n",
    ")\n",
    "\n",
    "fig = disp.figure_\n",
    "fig.set_figwidth(30)\n",
    "fig.set_figheight(30)\n",
    "\n",
    "plt.xlabel('Przewidziana Etykieta', fontsize=20)\n",
    "plt.ylabel('Prawdziwa Etykieta', fontsize=20)\n",
    "\n",
    "plt.xticks(fontsize=15, rotation=45, ha='right')\n",
    "plt.yticks(fontsize=15, rotation=0, va=\"center\")\n",
    "\n",
    "for text in disp.text_.ravel():\n",
    "    text.set_fontsize(14)\n",
    "\n",
    "plt.savefig('conf_mat_BEST_test.png')\n",
    "print(\"Plots saved as 'conf_mat_normalized_articles_based_no_norm.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e815007-8962-4bf4-a5c6-132e262818ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb52a0-552e-4cab-94af-9ab051fa1e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
